# -*- coding: utf-8 -*-
import os
import time
import random
import requests
import pandas as pd
import yfinance as yf
import json
from datetime import datetime
from io import StringIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from pathlib import Path

# ========== æ ¸å¿ƒåƒæ•¸è¨­å®š ==========
MARKET_CODE = "us-share"
DATA_SUBDIR = "dayK"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data", MARKET_CODE, DATA_SUBDIR)
# ğŸš€ æ–°å¢ï¼šæ¸…å–®å¿«å–è·¯å¾‘
CACHE_LIST_PATH = os.path.join(BASE_DIR, "us_stock_list_cache.json")

MAX_WORKERS = 5 
Path(DATA_DIR).mkdir(parents=True, exist_ok=True)

def log(msg: str):
    print(f"{pd.Timestamp.now():%H:%M:%S}: {msg}")

def classify_security(name: str, is_etf: bool) -> str:
    """éæ¿¾é‚è¼¯ï¼šåƒ…ä¿ç•™é«˜å“è³ªæ™®é€šè‚¡"""
    if is_etf: return "Exclude"
    n_upper = name.upper()
    exclude_keywords = ["WARRANT", "RIGHTS", "UNIT", "PREFERRED", "DEPOSITARY", "ADR", "FOREIGN", "DEBENTURE"]
    if any(kw in n_upper for kw in exclude_keywords): return "Exclude"
    return "Common Stock"

def get_full_stock_list():
    """
    âš¡ å¿«å–åŒ–æ¸…å–®ç²å–ï¼š
    è‹¥ä»Šæ—¥å·²æŠ“éæ¸…å–®å‰‡ç›´æ¥è®€å–ï¼Œä¸é‡è¤‡è«‹æ±‚ Nasdaq å®˜ç¶²
    """
    if os.path.exists(CACHE_LIST_PATH):
        file_mtime = os.path.getmtime(CACHE_LIST_PATH)
        # å¦‚æœæª”æ¡ˆæ˜¯ä»Šå¤©ç”¢ç”Ÿçš„ï¼Œå°±ç›´æ¥ç”¨
        if datetime.fromtimestamp(file_mtime).date() == datetime.now().date():
            log("ğŸ“¦ åµæ¸¬åˆ°ä»Šæ—¥å·²ç·©å­˜ç¾è‚¡æ¸…å–®ï¼Œç›´æ¥è¼‰å…¥...")
            with open(CACHE_LIST_PATH, "r", encoding="utf-8") as f:
                return json.load(f)

    log("ğŸ“¡ ç·©å­˜å¤±æ•ˆï¼Œé–‹å§‹å¾å®˜ç¶²ç²å–ç¾è‚¡æ™®é€šè‚¡æ¸…å–®...")
    all_rows = []

    # 1. NASDAQ
    try:
        r1 = requests.get("https://www.nasdaqtrader.com/dynamic/symdir/nasdaqlisted.txt", timeout=15)
        df1 = pd.read_csv(StringIO(r1.text), sep="|")
        df1 = df1[df1["Test Issue"] == "N"]
        df1["Category"] = df1.apply(lambda row: classify_security(row["Security Name"], row["ETF"] == "Y"), axis=1)
        f1 = df1[(df1["Market Category"].isin(["Q", "G"])) & (df1["Category"] == "Common Stock")]
        for _, row in f1.iterrows():
            all_rows.append(f"{str(row['Symbol']).strip().replace('$', '-')}&{str(row['Security Name']).strip()}")
    except Exception as e: log(f"âš ï¸ NASDAQ å¤±æ•—: {e}")

    # 2. NYSE/Other
    try:
        r2 = requests.get("https://www.nasdaqtrader.com/dynamic/symdir/otherlisted.txt", timeout=15)
        df2 = pd.read_csv(StringIO(r2.text), sep="|")
        df2 = df2[df2["Test Issue"] == "N"]
        df2["Category"] = df2.apply(lambda row: classify_security(row["Security Name"], row["ETF"] == "Y"), axis=1)
        f2 = df2[(df2["Exchange"] == "N") & (df2["Category"] == "Common Stock")]
        for _, row in f2.iterrows():
            all_rows.append(f"{str(row['NASDAQ Symbol']).strip().replace('$', '-')}&{str(row['Security Name']).strip()}")
    except Exception as e: log(f"âš ï¸ NYSE å¤±æ•—: {e}")

    final_list = list(set(all_rows))
    
    # å„²å­˜æ¸…å–®å¿«å–
    with open(CACHE_LIST_PATH, "w", encoding="utf-8") as f:
        json.dump(final_list, f, ensure_ascii=False)
        
    log(f"âœ… æ¸…å–®å·²æ›´æ–°ä¸¦å„²å­˜ï¼Œå…± {len(final_list)} æª”ã€‚")
    return final_list

def download_stock_data(item):
    """
    âš¡ æª”æ¡ˆç´šå¿«å–ï¼š
    è‹¥ç¡¬ç¢Ÿå·²å­˜åœ¨è©²ä»£è™Ÿ CSV ä¸”å¤§å°æ­£ç¢ºï¼Œç›´æ¥è·³éä¸‹è¼‰
    """
    try:
        parts = item.split('&', 1)
        if len(parts) < 2: return {"status": "error"}
        yf_tkr, name = parts
        safe_name = "".join([c for c in name if c.isalnum() or c in (' ', '_', '-')]).strip()
        out_path = os.path.join(DATA_DIR, f"{yf_tkr}_{safe_name}.csv")
        
        # âœ… å¿«å–æ ¸å¿ƒï¼šæª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if os.path.exists(out_path) and os.path.getsize(out_path) > 1000:
            return {"status": "exists", "tkr": yf_tkr}

        # --- è‹¥å¿«å–ä¸å­˜åœ¨æ‰åŸ·è¡Œä¸‹è¼‰ ---
        time.sleep(random.uniform(0.4, 1.2))
        tk = yf.Ticker(yf_tkr)
        
        for attempt in range(2):
            try:
                hist = tk.history(period="2y", timeout=20)
                if hist is not None and not hist.empty:
                    hist.reset_index(inplace=True)
                    hist.columns = [c.lower() for c in hist.columns]
                    hist.to_csv(out_path, index=False, encoding='utf-8-sig')
                    return {"status": "success", "tkr": yf_tkr}
            except Exception as e:
                if "Rate limited" in str(e): time.sleep(random.uniform(20, 40))
            time.sleep(random.uniform(3, 6))

        return {"status": "empty", "tkr": yf_tkr}
    except: return {"status": "error"}

def main():
    items = get_full_stock_list()
    if not items: return log("âŒ ç„¡æ¸…å–®ã€‚")

    log(f"ğŸš€ é–‹å§‹ç¾è‚¡ä»»å‹™ (é›™é‡å¿«å–å•Ÿå‹•ä¸­)")
    stats = {"success": 0, "exists": 0, "empty": 0, "error": 0}
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(download_stock_data, it): it for it in items}
        pbar = tqdm(total=len(items), desc="ç¾è‚¡é€²åº¦", unit="æª”")
        for future in as_completed(futures):
            res = future.result()
            stats[res.get("status", "error")] += 1
            pbar.update(1)
            # åªæœ‰åœ¨çœŸæ­£ä¸‹è¼‰(success)æ™‚æ‰éœ€è¦é•·ä¼‘çœ ï¼Œå¿«å–è·³éæ™‚ä¸éœ€è¦
        pbar.close()
    
    log(f"ğŸ“Š å ±å‘Š: æˆåŠŸ={stats['success']}, è·³é={stats['exists']}, ç„¡è³‡æ–™={stats['empty']}, å¤±æ•—={stats['error']}")

if __name__ == "__main__":
    main()
